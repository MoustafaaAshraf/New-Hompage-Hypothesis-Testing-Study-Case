<h1>Table of Contents<span class="tocSkip"></span></h1>
<div class="toc"><ul class="toc-item"><li><span><a href="#Scenario" data-toc-modified-id="Scenario-1"><span class="toc-item-num">1&nbsp;&nbsp;</span>Scenario</a></span></li><li><span><a href="#Specifying-the-Objective-of-the-study" data-toc-modified-id="Specifying-the-Objective-of-the-study-2"><span class="toc-item-num">2&nbsp;&nbsp;</span>Specifying the Objective of the study</a></span></li><li><span><a href="#Workflow" data-toc-modified-id="Workflow-3"><span class="toc-item-num">3&nbsp;&nbsp;</span>Workflow</a></span></li><li><span><a href="#Website-Structure" data-toc-modified-id="Website-Structure-4"><span class="toc-item-num">4&nbsp;&nbsp;</span>Website Structure</a></span></li><li><span><a href="#Building-Experiment-Funnel" data-toc-modified-id="Building-Experiment-Funnel-5"><span class="toc-item-num">5&nbsp;&nbsp;</span>Building Experiment Funnel</a></span></li><li><span><a href="#Unit-Of-Diversion" data-toc-modified-id="Unit-Of-Diversion-6"><span class="toc-item-num">6&nbsp;&nbsp;</span>Unit Of Diversion</a></span></li><li><span><a href="#Choosing-Metrics" data-toc-modified-id="Choosing-Metrics-7"><span class="toc-item-num">7&nbsp;&nbsp;</span>Choosing Metrics</a></span><ul class="toc-item"><li><ul class="toc-item"><li><span><a href="#The-Invariant-Mertic" data-toc-modified-id="The-Invariant-Mertic-7.0.1"><span class="toc-item-num">7.0.1&nbsp;&nbsp;</span>The Invariant Mertic</a></span></li><li><span><a href="#Evaluation-Metrics" data-toc-modified-id="Evaluation-Metrics-7.0.2"><span class="toc-item-num">7.0.2&nbsp;&nbsp;</span>Evaluation Metrics</a></span></li></ul></li></ul></li><li><span><a href="#Experiment-Feasability" data-toc-modified-id="Experiment-Feasability-8"><span class="toc-item-num">8&nbsp;&nbsp;</span>Experiment Feasability</a></span><ul class="toc-item"><li><ul class="toc-item"><li><span><a href="#Current-Layout-Statistics" data-toc-modified-id="Current-Layout-Statistics-8.0.1"><span class="toc-item-num">8.0.1&nbsp;&nbsp;</span>Current Layout Statistics</a></span></li><li><span><a href="#Experiment-Type-I-error-&amp;-Bonferroni-Correction" data-toc-modified-id="Experiment-Type-I-error-&amp;-Bonferroni-Correction-8.0.2"><span class="toc-item-num">8.0.2&nbsp;&nbsp;</span>Experiment Type I error &amp; Bonferroni Correction</a></span></li></ul></li></ul></li><li><span><a href="#Suitable-Experiment-to-detect-changes-in-downloads" data-toc-modified-id="Suitable-Experiment-to-detect-changes-in-downloads-9"><span class="toc-item-num">9&nbsp;&nbsp;</span>Suitable Experiment to detect changes in downloads</a></span></li><li><span><a href="#Suitable-Experiment-to-detect-changes-in-License-purchasing" data-toc-modified-id="Suitable-Experiment-to-detect-changes-in-License-purchasing-10"><span class="toc-item-num">10&nbsp;&nbsp;</span>Suitable Experiment to detect changes in License purchasing</a></span></li><li><span><a href="#Invariant-Metric" data-toc-modified-id="Invariant-Metric-11"><span class="toc-item-num">11&nbsp;&nbsp;</span>Invariant Metric</a></span></li><li><span><a href="#Evaluation-Metrics" data-toc-modified-id="Evaluation-Metrics-12"><span class="toc-item-num">12&nbsp;&nbsp;</span>Evaluation Metrics</a></span><ul class="toc-item"><li><ul class="toc-item"><li><span><a href="#Downloads-Significance" data-toc-modified-id="Downloads-Significance-12.0.1"><span class="toc-item-num">12.0.1&nbsp;&nbsp;</span>Downloads Significance</a></span></li><li><span><a href="#Purchasing-Significance" data-toc-modified-id="Purchasing-Significance-12.0.2"><span class="toc-item-num">12.0.2&nbsp;&nbsp;</span>Purchasing Significance</a></span></li></ul></li></ul></li><li><span><a href="#Draw-Conclusions" data-toc-modified-id="Draw-Conclusions-13"><span class="toc-item-num">13&nbsp;&nbsp;</span>Draw Conclusions</a></span></li></ul></div>

# Homepage Introduction Study Case

## Scenario

- Productivity software company that is looking for ways to increase the number of people who pay for their software. The way that the software is currently set up, users can download and use the software free of charge, for a 7-day trial. After the end of the trial, users are required to pay for a license to continue using the software. 


- One idea that the company wants to try is to change the layout of the homepage to emphasize more prominently and higher up on the page that there is a 7-day trial available for the company's software. The current fear is that some potential users are missing out on using the software because of a lack of awareness of the trial period. If more people download the software and use it in the trial period, the hope is that this entices more people to make a purchase after seeing what the software can do.

## Specifying the Objective of the study

- Does changing the structure of the homepage would increase the number of downloads of the software and, ultimately, the number of purchases of the software.

## Workflow

- In this case study, I will go through the whole process of setting up a hypothesis testing scenario to know scientifically if the the new homepage is worth implementing or not.

- The steps to perform the study case are as follows:
> 1. Constructing a user funnel and deciding on metrics to track.
> 2. Experiment sizing with regard to how the traffic rate and the period of the experiment.
> 3. Perform statistical tests to analyze the results.
> 4. Constructing conclusions.

## Website Structure

- The website has 5 main sections:
> 1. The homepage
> 2. Additional information section, gallery, and examples.
> 3. Download page.
> 4. Purchasing page.
> 5. Support and FAQs.


- To download the software, the user is required to create an account, which allows using for 7 days. After the 7 days, the software would bring up a message that takes the user to the Purchasing page.

## Building Experiment Funnel

- Expected Flow of users:
> 1. Visit Homepage
> 2. Visit download page
> 3. Creating an account
> 4. Downloading the software
> 5. After 7 days trial, user is directed to license purchasing page.
> 6. Purchasing software license

- There could be unexpected use route that is not within the expected flow. Anticipating scenarios like this can be useful for planning the design, and coming up with metrics that come as close as possible to measuring desired effects. 

## Unit Of Diversion

- From our user funnel, we choose our metrics and how they are measured.
- To assure Contruct Validity of the experiment, the participants are split into experiment and control groups. 
- The point of splitting up the participants, called, Unit Of Diversion, which would be **cookie-based diversion**.


## Choosing Metrics

#### The Invariant Mertic

- **The number of cookies that hit the homepage**.
- If we've done things correctly, each visitor should have an equal chance of seeing each homepage, and that means that the number of cookies assigned to each group should be about the same. Since visitors come in without any additional information (e.g. account info) and the change effected by the experimental manipulation comes in right at the start, there aren't other invariant metrics we should worry about.

#### Evaluation Metrics

- It pretty intutive to take evaluation metric based on counts, count of download or counts of purchases, though we expect the number of cookies assigned to each group to be about the same, it's much more likely than not they they won't be exactly the same.

- Instead, we should prefer using the **download rate (# downloads / # cookies)** and **purchase rate (# licenses / # cookies)** relative to the number of cookies as evaluation metrics. Using these ratios allows us to account for slight imbalances between groups.

## Experiment Feasability


#### Current Layout Statistics

- looking at the feasibility of the experiment in terms of the amount of time it will take to run, We can use historical data as a baseline to see what it might take to detect our desired levels of change.

- Recent history shows that there are about **3250 unique visitors per day**, with slightly more visitors on Friday through Monday, than the rest of the week. There are about **520 software downloads per day (a .16 rate)** and about **65 licenses purchased each day (a .02 rate)**. In an ideal case, both the download rate and license purchase rate should increase with the new homepage; a statistically significant negative change should be a sign to not deploy the homepage change. However, if only one of our metrics shows a statistically significant positive change we should be happy enough to deploy the new homepage.

- Experiment Running time would be done using Python. 
- The calculations have shown that to detect reasonable change in downloads, 10907 visitors should be testing in each group. According to the average traffic on the website, on most of the days the site receives 3250 visitors, which makes the experiment running time for downloads is 6 days.
- However, to detect reasnable changes in the Purchasing rates, for a change would be so tiny, the experiment needs to be run for 21 days. 

#### Experiment Type I error & Bonferroni Correction

- Because we have two evaluation metrics of interest, we should make sure that we are choosing an appropriate significance level to conduct each test, in order to preserve a maximum overall Type I error rate of .05. Since we would be happy to deploy the new homepage if either download rate or license purchase rate showed a statistically significant increase, performing both individual tests at a **.05 error rate** carries the risk of making too many Type I errors. As such, we'll apply the Bonferroni correction to run each test at a **.025 error rate** so as to protect against making too many errors. If it were the case that we needed to see both metrics with a statistically significant increase, then we wouldn't need to include the correction on the individual tests.

- As the most common sought for **test power is 80%**, we also should utilize that. 


